// TODO: all you need to dump the store as log messages

use itertools::Itertools as _;
use re_log_types::{
    external::arrow2_convert::deserialize::{arrow_array_deserialize_iterator, TryIntoCollection},
    msg_bundle::{wrap_in_listarray, Component, ComponentBundle, MsgBundle},
    ComponentName, MsgId, TimePoint,
};

use crate::DataStore;

// ---

impl DataStore {
    // TODO
    /// Panics if no index is present for `id_key` or if it isn't fully dense (i.e.: no empty
    /// rows and no empty columns!).
    pub fn as_msg_bundles(&self, id_key: ComponentName) -> impl Iterator<Item = MsgBundle> + '_ {
        self.dump_timeless_indices(id_key)
    }

    /// Panics if no index is present for `id_key` or if it isn't fully dense (i.e.: no empty
    /// rows and no empty columns!).
    fn dump_timeless_indices(&self, id_key: ComponentName) -> impl Iterator<Item = MsgBundle> + '_ {
        let msg_bundles = self.timeless_indices.values().map(|index| {
            //     pub msg_id: MsgId,
            //     pub components: Vec<ComponentBundle>,

            //     pub entity_path: EntityPath,
            let ent_path = index.ent_path.clone();

            //     pub time_point: TimePoint,
            let timepoint = TimePoint::timeless();

            // TODO: could compact at this point
            // TODO: that's once we support batching tho

            // Gather all component indices, except for the internal `insert_id` one.
            let all_indices = index
                .indices
                .iter()
                // Definitely should _not_ dump insert IDs
                .filter(|(component, _)| **component != DataStore::insert_id_key())
                .collect_vec();

            // Find the index used to identify messages (i.e. `MsgId` in the case of Rerun).
            //
            // We currently need to fetch those to be able to create the final `MsgBundle`.
            // This is an artifact of the past and should go away as we implement batch support.
            //
            // Reminder: the store is not aware of message identification, this entirely up to
            // the application layer.
            //
            // It's up to the application layer to guarantee the presence of this index: this will
            // panic otherwise.
            let ids_index = &index.indices[&id_key];
            let ids_table = &self.timeless_components[&id_key];
            let ids = ids_index
                .iter()
                .map(|row_idx| row_idx.map(|row_idx| ids_table.get(row_idx)));

            let mut all_tables = Vec::with_capacity(all_indices.len());
            for (component, index) in &all_indices {
                let table = &self.timeless_components[*component]; // TODO
                all_tables.push((
                    *component,
                    index
                        .iter()
                        .map(|row_idx| row_idx.map(|row_idx| table.get(row_idx))),
                ));
            }

            // TODO: shouldnt embed autogenerated keys.. we know it's an autogenerated one if its
            // row index can be found in the cluster_comp_cache

            ids.map(move |msg_ids| {
                // It's up to the application layer to guarantee the row-density of this
                // index: this will panic otherwise.
                let msg_ids = msg_ids.unwrap();

                // Again, this is an artifact of the past: we need to deserialize the raw message
                // IDs in order to create actual `MsgBundle`s.
                // This'll go away with batching.
                //
                // NOTE: Reminder that we don't _really_ support splats, so a row with N instances
                // will actually have N message IDs.
                let msg_ids: Vec<MsgId> = TryIntoCollection::try_into_collection(msg_ids).unwrap();

                let components = all_tables
                    .iter_mut()
                    .filter_map(|(component, index)| {
                        index
                            .next()
                            .flatten()
                            .map(|data| (**component, wrap_in_listarray(data)))
                    })
                    .map(|(component, data)| ComponentBundle::new(component, data))
                    .collect_vec();

                MsgBundle {
                    // It's up to the application layer to guarantee the column-density of this
                    // index: this will panic otherwise.
                    msg_id: msg_ids[0],
                    entity_path: ent_path.clone(),
                    time_point: timepoint.clone(),
                    components,
                }
            })
        });

        msg_bundles.kmerge_by(|bundle1, bundle2| bundle1.msg_id < bundle2.msg_id)
    }
}
